import { Command } from 'commander';
import path from 'path';
import { ConfigManager } from '../../utils/config.js';
import { DatabaseService } from '../../services/database.js';
import { DocumentService } from '../../services/document.js';
import { ContextService } from '../../services/context.js';
import { EmbeddingService } from '../../services/embedding.js';
import { OpenAIProvider } from '../../providers/openai.js';
import { ProgressIndicator, ProgressBar, formatDuration, formatFileSize } from '../utils/progress.js';
import { validateFilePath, formatValidationError } from '../utils/validation.js';
import { promptConfirm } from '../utils/input.js';

export function createAddCommand(): Command {
  return new Command('add')
    .description('Add a document to the knowledge base with full processing pipeline')
    .argument('<file>', 'Path to the document file to add')
    .option('--config-path <path>', 'Path to configuration file')
    .option('--skip-context', 'Skip context generation step')
    .option('--skip-embedding', 'Skip embedding generation step')
    .option('--force', 'Overwrite existing document with same content hash')
    .option('--dry-run', 'Show what would be done without actually processing')
    .action(async (file, options) => {
      try {
        await addDocument(file, options);
      } catch (error) {
        console.error(formatValidationError(error));
        process.exit(1);
      }
    });
}

async function addDocument(
  filePath: string, 
  options: { 
    configPath?: string; 
    skipContext?: boolean;
    skipEmbedding?: boolean;
    dryRun?: boolean;
    force?: boolean;
  }
): Promise<void> {
  const startTime = Date.now();
  
  console.log('üìÑ RAG Tool Document Ingestion');
  console.log('');

  // Validate file path
  validateFilePath(filePath);

  const absolutePath = path.resolve(filePath);
  console.log('üìÅ File:', absolutePath);

  // Load configuration
  const configManager = new ConfigManager(options.configPath);
  
  if (!configManager.exists()) {
    console.error('‚ùå Configuration not found. Run "rag-tool init" first.');
    process.exit(1);
  }

  const config = await configManager.load();

  // Initialize services
  const dbService = new DatabaseService(config.database.path);
  
  if (!dbService.isInitialized()) {
    const progress = new ProgressIndicator('Initializing database connection...');
    progress.start();
    
    try {
      await dbService.initialize();
      progress.stop('Database connected');
    } catch (error) {
      progress.fail('Database connection failed');
      throw new Error('Database not initialized. Run "rag-tool db-init" first.');
    }
  }

  // Initialize AI providers
  let openaiProvider: OpenAIProvider | undefined;
  if (config.providers.openai) {
    openaiProvider = new OpenAIProvider(config.providers.openai.apiKey);
  }

  if (!openaiProvider) {
    throw new Error('OpenAI provider not configured. Check your configuration.');
  }

  const documentService = new DocumentService(dbService, {
    chunking: config.chunking,
    validateContent: true,
    extractMetadata: true,
  });

  const contextService = new ContextService(openaiProvider, dbService, {
    provider: 'openai',
    model: config.providers.openai?.contextModel || 'gpt-4o-mini',
    maxTokens: config.contextGeneration.maxContextTokens,
    enableCaching: true,
  });

  const embeddingService = new EmbeddingService(openaiProvider, dbService, {
    provider: 'openai',
    model: config.providers.openai?.embeddingModel || 'text-embedding-3-small',
  });

  try {
    // Step 1: Process document and create chunks
    console.log('');
    console.log('üìù Step 1: Document Processing');
    
    if (options.dryRun) {
      console.log('üîç Dry run mode - analyzing file...');
      const fileStats = await getFileStats(absolutePath);
      console.log(`  üìä File size: ${formatFileSize(fileStats.size)}`);
      console.log(`  ‚öôÔ∏è  Chunking strategy: ${config.chunking.strategy}`);
      console.log(`  üìè Chunk size: ${config.chunking.chunkSize} characters`);
      console.log(`  üîÑ Overlap: ${config.chunking.overlap} characters`);
      
      // Perform actual chunking analysis without storing
      console.log('');
      console.log('üß™ Performing chunking analysis...');
      
      try {
        const dryRunResult = await performDryRunAnalysis(absolutePath, config.chunking);
        
        console.log('');
        console.log('üìã Chunking Analysis Results:');
        console.log(`  üìù Original content length: ${dryRunResult.contentLength.toLocaleString()} characters`);
        console.log(`  ‚úÇÔ∏è  Total chunks created: ${dryRunResult.chunks.length}`);
        console.log(`  üìä Average chunk size: ${Math.round(dryRunResult.avgChunkSize)} characters`);
        console.log(`  üìè Min chunk size: ${dryRunResult.minChunkSize} characters`);
        console.log(`  üìê Max chunk size: ${dryRunResult.maxChunkSize} characters`);
        console.log(`  üîÑ Total overlap: ${dryRunResult.totalOverlap} characters`);
        
        console.log('');
        console.log('üéØ API Calls that would be made:');
        if (!options.skipContext) {
          console.log(`  üß† Context generation: ${dryRunResult.chunks.length} calls to ${config.providers.openai?.contextModel || 'gpt-4o-mini'}`);
          console.log(`    üìä Est. tokens per call: ~${Math.ceil((dryRunResult.contentLength + dryRunResult.avgChunkSize) / 4)}`);
          console.log(`    üí∞ Est. total tokens: ~${Math.ceil((dryRunResult.contentLength + dryRunResult.avgChunkSize) * dryRunResult.chunks.length / 4).toLocaleString()}`);
        }
        if (!options.skipEmbedding) {
          console.log(`  üî¢ Embedding generation: ${dryRunResult.chunks.length} calls to ${config.providers.openai?.embeddingModel || 'text-embedding-3-small'}`);
          console.log(`    üìä Est. tokens per call: ~${Math.ceil(dryRunResult.avgChunkSize / 4)}`);
          console.log(`    üí∞ Est. total tokens: ~${Math.ceil(dryRunResult.avgChunkSize * dryRunResult.chunks.length / 4).toLocaleString()}`);
        }
        
        console.log('');
        console.log('üëÜ Use without --dry-run to actually process the document');
        
      } catch (error) {
        console.error('‚ùå Chunking analysis failed:', error instanceof Error ? error.message : String(error));
      }
      
      return;
    }

    const docProgress = new ProgressIndicator('Processing document and creating chunks...');
    docProgress.start();

    const processingResult = await documentService.processDocumentFromFile(absolutePath);
    
    docProgress.stop(`Document processed: ${processingResult.chunks.length} chunks created`);

    console.log('');
    console.log('üìã Document Processing Results:');
    console.log(`  üìÑ Document ID: ${processingResult.document.id}`);
    console.log(`  üìù Total chunks: ${processingResult.chunks.length}`);
    console.log(`  üìä Word count: ${processingResult.metadata?.wordCount || 'N/A'}`);
    console.log(`  üî§ Character count: ${processingResult.metadata?.characterCount || 'N/A'}`);
    console.log(`  üéØ Estimated tokens: ${processingResult.metadata?.estimatedTokens || 'N/A'}`);
    console.log(`  üèóÔ∏è  Has structure: ${processingResult.metadata?.hasStructure ? 'Yes' : 'No'}`);

    // Check for existing document
    if (!options.force) {
      const existingDoc = dbService.getDocumentByHash(processingResult.document.content_hash);
      if (existingDoc && existingDoc.id !== processingResult.document.id) {
        console.log('');
        console.log('‚ö†Ô∏è  Document with same content already exists.');
        const overwrite = await promptConfirm('Do you want to continue anyway?', false);
        if (!overwrite) {
          console.log('Document addition cancelled.');
          return;
        }
      }
    }

    // Step 2: Generate context for chunks (optional)
    if (!options.skipContext) {
      console.log('');
      console.log('üß† Step 2: Context Generation');
      
      const contextProgress = new ProgressBar(
        processingResult.chunks.length,
        'Generating context for chunks...'
      );

      const contextResult = await contextService.generateContextsForDocument(
        processingResult.document.id
      );

      contextProgress.finish('Context generation complete');

      console.log('');
      console.log('üìã Context Generation Results:');
      console.log(`  ‚úÖ Successful: ${contextResult.successCount}`);
      console.log(`  ‚ùå Failed: ${contextResult.failureCount}`);
      console.log(`  üí∞ Tokens used: ${contextResult.totalTokensUsed}`);
      console.log(`  ‚ö° Cache hits: ${contextResult.cacheHitCount}`);

      if (contextResult.failureCount > 0) {
        console.log('');
        console.log('‚ö†Ô∏è  Some chunks failed context generation. Check the errors above.');
        const continueProcessing = await promptConfirm('Continue with embedding generation?', true);
        if (!continueProcessing) {
          console.log('Processing stopped. You can resume later with the same command.');
          return;
        }
      }
    } else {
      console.log('');
      console.log('‚è≠Ô∏è  Skipping context generation (--skip-context)');
    }

    // Step 3: Generate embeddings (optional)
    if (!options.skipEmbedding) {
      console.log('');
      console.log('üî¢ Step 3: Embedding Generation');
      
      const embeddingProgress = new ProgressBar(
        processingResult.chunks.length,
        'Generating embeddings for chunks...'
      );

      const embeddingResult = await embeddingService.generateEmbeddingsForDocument(
        processingResult.document.id
      );

      embeddingProgress.finish('Embedding generation complete');

      console.log('');
      console.log('üìã Embedding Generation Results:');
      console.log(`  ‚úÖ Successful: ${embeddingResult.successCount}`);
      console.log(`  ‚ùå Failed: ${embeddingResult.failureCount}`);
      console.log(`  üí∞ Tokens used: ${embeddingResult.totalTokensUsed}`);

      if (embeddingResult.failureCount > 0) {
        console.log('');
        console.log('‚ö†Ô∏è  Some chunks failed embedding generation. The document is still searchable with successful chunks.');
      }
    } else {
      console.log('');
      console.log('‚è≠Ô∏è  Skipping embedding generation (--skip-embedding)');
    }

    // Final status update
    const finalStatus: 'complete' | 'processing' = options.skipEmbedding ? 'processing' : 'complete';
    await documentService.updateDocumentStatus(
      processingResult.document.id,
      finalStatus,
      processingResult.chunks.length
    );

    // Summary
    const totalTime = Date.now() - startTime;
    console.log('');
    console.log('‚úÖ Document processing complete!');
    console.log('');
    console.log('üìä Summary:');
    console.log(`  ‚è±Ô∏è  Total time: ${formatDuration(totalTime)}`);
    console.log(`  üìÑ Document: ${path.basename(absolutePath)}`);
    console.log(`  üÜî Document ID: ${processingResult.document.id}`);
    console.log(`  üìù Chunks: ${processingResult.chunks.length}`);
    console.log(`  üîç Status: ${finalStatus}`);
    console.log('');
    console.log('Next steps:');
    console.log(`  üîç Search: rag-tool search "your query"`);
    console.log(`  üìã List: rag-tool list`);
    console.log('');
  } finally {
    dbService.close();
  }
}

async function getFileStats(filePath: string): Promise<{ size: number }> {
  const fs = require('fs').promises;
  const stats = await fs.stat(filePath);
  return { size: stats.size };
}

async function performDryRunAnalysis(filePath: string, chunkingOptions: any): Promise<{
  contentLength: number;
  chunks: Array<{ text: string; startPosition: number; endPosition: number; index: number }>;
  avgChunkSize: number;
  minChunkSize: number;
  maxChunkSize: number;
  totalOverlap: number;
}> {
  const fs = require('fs').promises;
  const { TextProcessor } = require('../../utils/text-processing.js');
  const { TextChunker } = require('../../utils/chunking.js');
  
  // Read and process the file
  const content = await fs.readFile(filePath, 'utf8');
  const extractedText = TextProcessor.extractText(content, 'txt');
  
  // Perform chunking
  const chunker = new TextChunker(chunkingOptions);
  const chunks = chunker.chunk(extractedText);
  
  // Calculate statistics
  const chunkSizes = chunks.map((chunk: any) => chunk.text.length);
  const avgChunkSize = chunkSizes.reduce((sum: number, size: number) => sum + size, 0) / chunks.length;
  const minChunkSize = Math.min(...chunkSizes);
  const maxChunkSize = Math.max(...chunkSizes);
  
  // Calculate total overlap (approximate)
  const totalContentInChunks = chunkSizes.reduce((sum: number, size: number) => sum + size, 0);
  const totalOverlap = totalContentInChunks - extractedText.length;
  
  return {
    contentLength: extractedText.length,
    chunks,
    avgChunkSize,
    minChunkSize,
    maxChunkSize,
    totalOverlap: Math.max(0, totalOverlap)
  };
}